#分离训练数据集和评估数据集#

这是一种非常简洁，快速的数据分离技术，通常在具有大量数据、数据分布比较均衡，或者对问题的展示比较平均的情况下非常有效

#K折交叉验证#

将原始数据分成K组（一般是均分），将每个子集数据分别做一次验证集，其余的K-1组子集数据作为训练集，这样会得到K个模型，再用这K个模型最终的验证集的分类准确率
的平均数，作为此K折交叉验证下分类器的性能指标。K一般大于等于2，实际操作时一般从3开始取值，只有在原始数据集和数据量小的时候才会尝试取2.K折交叉验证可以有
效地避免过学习及欠学习状态的发生，最后得到的结果也比较具有说服力。通常情况下，K的取值为3、5、10.

#弃一交叉验证#

如果原始数据有N个样本，那么弃一验证就是N-1个交叉验证，即每个样本单独作为验证集，其余的N-1个样本作为训练集，所以弃一交叉验证会得到N个模型，用这N个模型最
终的验证集的分类准确率的平均数作为此次弃一交叉验证分类器的性能指标。相较于K折交叉验证，弃一交叉验证有两个显著的优点：
#每一回合中几乎所有的样本皆用于训练模型，因此最接近原始样本的分布，这样评估所得的结果比较可靠；
#实验过程中没有随机因素会影响实验数据，确保实验过程是可以被复制的
它的缺点是计算成本高


黄金准则：当不知道如何选择分离数据集的方法时，请选择K折交叉验证来分离数据集；当不知道如何设定K值时，请将K值设为10.
